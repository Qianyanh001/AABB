import os
import numbers
import torch
from torch.utils.data import Dataset
from torchvision import transforms
import mxnet as mx
import numpy as np
from PIL import Image

class FaceDataset(Dataset):
    def __init__(self, root_dir, mode='train', target_size=224, num_classes=600, images_per_class=20):
        """
        Args:
            root_dir (str): æ•°æ®é›†æ ¹ç›®å½• (åŒ…å« train.rec, train.idx)
            mode (str): 'train'
            target_size (int): è¾“å‡ºå›¾åƒå°ºå¯¸ (ViT å»ºè®® 224)
            num_classes (int): éœ€è¦ç­›é€‰çš„æ€»äººæ•° (é»˜è®¤ 600)
            images_per_class (int): æ¯äººæŠ½å–çš„å›¾åƒå¼ æ•° (é»˜è®¤ 20)
        """
        super(FaceDataset, self).__init__()
        self.root_dir = root_dir
        self.target_size = target_size
        
        path_imgrec = os.path.join(root_dir, 'train.rec')
        path_imgidx = os.path.join(root_dir, 'train.idx')
        
        if not os.path.exists(path_imgrec) or not os.path.exists(path_imgidx):
            raise RuntimeError(f"Dataset files not found in {root_dir}. Please check the path.")

        # 1. åŠ è½½ MXNet RecordIO
        self.imgrec = mx.recordio.MXIndexedRecordIO(path_imgidx, path_imgrec, 'r')
        
        # 2. è¯»å– Root Header (Index 0)
        # åœ¨ InsightFace æ ¼å¼ä¸­ï¼Œindex 0 å­˜å‚¨äº†èº«ä»½ç´¢å¼•çš„èŒƒå›´
        s = self.imgrec.read_idx(0)
        header, _ = mx.recordio.unpack(s)
        
        if header.flag > 0:
            # èŽ·å–èº«ä»½æ ‡è¯†(Identity)çš„ç´¢å¼•èŒƒå›´
            # id_start æ˜¯ç¬¬ä¸€ä¸ªäººçš„ç´¢å¼•ä½ç½®ï¼Œid_end æ˜¯æœ€åŽä¸€ä¸ªäººçš„ä½ç½®
            self.id_start = int(header.label[0])
            self.id_end = int(header.label[1])
            print(f"ðŸ”¥ Found {self.id_end - self.id_start} identities in total.")
        else:
            raise RuntimeError("The dataset is not in the standard indexed format. Cannot filter by Identity.")

        # 3. ç­›é€‰æ•°æ®ï¼š600äºº x 20å¼ 
        self.filtered_img_indices = []
        self.remapped_labels = []
        
        print(f"ðŸ” Filtering: Selecting {num_classes} IDs with at least {images_per_class} images each...")
        
        actual_class_count = 0
        for i in range(self.id_start, self.id_end):
            # è¯»å–è¯¥èº«ä»½å¯¹åº”çš„ Headerï¼Œheader.label å­˜å‚¨äº†è¯¥äººæ‰€æœ‰å›¾ç‰‡çš„ç´¢å¼•èŒƒå›´
            s = self.imgrec.read_idx(i)
            h, _ = mx.recordio.unpack(s)
            
            # èŽ·å–è¯¥ ID çš„å›¾ç‰‡ç´¢å¼•åŒºé—´ [start, end)
            img_idx_range = np.arange(int(h.label[0]), int(h.label[1]))
            
            if len(img_idx_range) >= images_per_class:
                # é€‰å–å‰ images_per_class å¼ å›¾
                selected_indices = img_idx_range[:images_per_class]
                self.filtered_img_indices.extend(selected_indices)
                
                # å…³é”®ï¼šæ‰§è¡Œæ ‡ç­¾é‡æ˜ å°„ï¼Œå°†åŽŸå§‹ ID æ˜ å°„ä¸º 0 ~ (num_classes - 1)
                self.remapped_labels.extend([actual_class_count] * images_per_class)
                
                actual_class_count += 1
                if actual_class_count >= num_classes:
                    break
        
        if actual_class_count < num_classes:
            print(f"âš ï¸ Warning: Only found {actual_class_count} classes meeting the requirement.")

        print(f"âœ… Final Dataset: {actual_class_count} classes, {len(self.filtered_img_indices)} total images.")

        # 4. æ•°æ®å¢žå¼º
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((target_size, target_size), interpolation=Image.BICUBIC),
            transforms.ToTensor(),
            # ä½¿ç”¨ BLIP-2/CLIP æ ‡å‡†å‡å€¼æ–¹å·®
            transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], 
                                 std=[0.26862954, 0.26130258, 0.27577711]),
        ])

    def __getitem__(self, index):
        # èŽ·å–å›¾ç‰‡ç´¢å¼•å’Œé‡æ˜ å°„åŽçš„æ ‡ç­¾
        img_idx = self.filtered_img_indices[index]
        label = self.remapped_labels[index]
        
        # è¯»å–å›¾ç‰‡æ•°æ®
        s = self.imgrec.read_idx(img_idx)
        _, img = mx.recordio.unpack(s)
        
        # è§£ç å¹¶è½¬æ¢
        sample = mx.image.imdecode(img).asnumpy()
        if self.transform is not None:
            sample = self.transform(sample)
            
        return sample, torch.tensor(label, dtype=torch.long)

    def __len__(self):
        return len(self.filtered_img_indices)

# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # å¡«å…¥ä½ çš„æ•°æ®é›†è·¯å¾„è¿›è¡ŒéªŒè¯
    DATA_ROOT = "./datasets/faces_emore" 
    try:
        ds = FaceDataset(DATA_ROOT, num_classes=600, images_per_class=20)
        img, lbl = ds[0]
        print(f"Image shape: {img.shape}, Label: {lbl}")
        
        # éªŒè¯æ ‡ç­¾èŒƒå›´
        all_labels = np.array(ds.remapped_labels)
        print(f"Label range: {all_labels.min()} to {all_labels.max()}")
        print(f"Unique labels: {len(np.unique(all_labels))}")
    except Exception as e:
        print(f"Setup failed: {e}")

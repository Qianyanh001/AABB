import os
import numbers
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import mxnet as mx
import numpy as np
from PIL import Image
class FaceDataset(Dataset):
    def __init__(self, root_dir, mode='train', target_size=112, max_samples=None):
        """
        Args:
            root_dir (str): æ•°æ®é›†æ ¹ç›®å½•
            mode (str): 'train'
            target_size (int): 
                - å¦‚æœæ˜¯ iResNetï¼Œå¿…é¡»è®¾ä¸º 112
                - å¦‚æœæ˜¯ ViTï¼Œé€šå¸¸è®¾ä¸º 224
            max_samples (int): å¼ºåˆ¶åªä½¿ç”¨å‰ N å¼ å›¾ç‰‡ã€‚
        """
        super(FaceDataset, self).__init__()
        self.root_dir = root_dir
        self.target_size = target_size
        
        path_imgrec = os.path.join(root_dir, 'train.rec')
        path_imgidx = os.path.join(root_dir, 'train.idx')
        if not os.path.exists(path_imgrec) or not os.path.exists(path_imgidx):
            raise RuntimeError(f"Dataset files not found in {root_dir}")
        # 1. åŠ è½½ MXNet RecordIO
        self.imgrec = mx.recordio.MXIndexedRecordIO(path_imgidx, path_imgrec, 'r')
        # 2. è¯»å– Header
        s = self.imgrec.read_idx(0)
        header, _ = mx.recordio.unpack(s)
        
        # 3. è·å–æ‰€æœ‰å›¾ç‰‡ç´¢å¼•
        if header.flag > 0:
            max_idx = int(header.label[0])
            self.imgidx = np.array(range(1, max_idx))
        else:
            self.imgidx = np.array(list(self.imgrec.keys))
        # 4. [Lite Mode] å¼ºåˆ¶æˆªæ–­æ•°æ®é‡
        if max_samples is not None and max_samples < len(self.imgidx):
            self.imgidx = self.imgidx[:max_samples]
            print(f"âš¡ [Lite Mode] Dataset truncated to first {max_samples} images only.")
        else:
            print(f"ğŸ“š [Full Mode] Using all {len(self.imgidx)} images.")
        # 5. æ•°æ®å¢å¼º
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ ¹æ® target_size åŠ¨æ€è°ƒæ•´ Resize
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((target_size, target_size), interpolation=Image.BICUBIC),
            # transforms.RandomHorizontalFlip(p=0.5), # æå–æ•™å¸ˆç‰¹å¾å»ºè®®å…³é—­ç¿»è½¬ï¼Œä¿æŒç¡®å®šæ€§
            transforms.ToTensor(),
            # æ”¹ä¸º BLIP-2/CLIP æ ‡å‡†å‡å€¼æ–¹å·®
            transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], 
                                 std=[0.26862954, 0.26130258, 0.27577711]),
        ])
    def __getitem__(self, index):
        idx = self.imgidx[index]
        s = self.imgrec.read_idx(idx)
        header, img = mx.recordio.unpack(s)
        
        label = header.label
        if not isinstance(label, numbers.Number):
            label = label[0]
        label = torch.tensor(label, dtype=torch.long)
        sample = mx.image.imdecode(img).asnumpy()
        if self.transform is not None:
            sample = self.transform(sample)
            
        return sample, label
    def __len__(self):
        return len(self.imgidx)
